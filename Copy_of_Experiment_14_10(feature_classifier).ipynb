{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSPX0hTUMjJ4BLhRGAzaWK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmed-M2020/zer0p_notebooks/blob/main/Copy_of_Experiment_14_10(feature_classifier).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt1HFeo7fWK-",
        "outputId": "26bcefc4-d1c6-4dc1-ea2a-70ea5154a64d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tqdm\n",
        "from torch.optim import lr_scheduler\n",
        "from tqdm import tqdm\n",
        "# Pytorch\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/filtered_data/final_filtered_df.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "# df['Label'] = df['Label'].replace({'good': 1, 'bad': 0})\n",
        "df.drop(columns=['Label'], inplace=True)\n",
        "df.head()\n",
        "# df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "O3PjKOtLfdVO",
        "outputId": "c67ecdbe-d71b-4620-b6da-f046cfba2eee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 Surface Treatment [bbuchr; msahac]    Acc  Resolution [dpi]  \\\n",
              "0           0                             bbuchr  150.0             300.0   \n",
              "1           1                             bbuchr  150.0             300.0   \n",
              "2           2                             bbuchr  150.0             300.0   \n",
              "3           3                             bbuchr  150.0             300.0   \n",
              "4           4                             bbuchr  150.0             300.0   \n",
              "\n",
              "   Rounding [AV]  Speed [mm/s]  Tep [°C] Head Gap [mm]  \\\n",
              "0          100.0          50.0      42.0             1   \n",
              "1          100.0          50.0      42.0             1   \n",
              "2          100.0          50.0      42.0             1   \n",
              "3          100.0          50.0      42.0             1   \n",
              "4          100.0          50.0      42.0             1   \n",
              "\n",
              "                                File    Feature  \\\n",
              "0  230523_Dataset01_Valeo_Nr01_0.png     dist.1   \n",
              "1  230523_Dataset01_Valeo_Nr01_0.png  e.rought1   \n",
              "2  230523_Dataset01_Valeo_Nr01_1.png  e.rought2   \n",
              "3  230523_Dataset01_Valeo_Nr01_1.png  e.rought3   \n",
              "4  230523_Dataset01_Valeo_Nr01_2.png      angle   \n",
              "\n",
              "                                       absolute_path  \n",
              "0  /content/drive/MyDrive/zerop/FTI Dataset 2023/...  \n",
              "1  /content/drive/MyDrive/zerop/FTI Dataset 2023/...  \n",
              "2  /content/drive/MyDrive/zerop/FTI Dataset 2023/...  \n",
              "3  /content/drive/MyDrive/zerop/FTI Dataset 2023/...  \n",
              "4  /content/drive/MyDrive/zerop/FTI Dataset 2023/...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba564009-291d-4568-992e-7d3989277f0b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Surface Treatment [bbuchr; msahac]</th>\n",
              "      <th>Acc</th>\n",
              "      <th>Resolution [dpi]</th>\n",
              "      <th>Rounding [AV]</th>\n",
              "      <th>Speed [mm/s]</th>\n",
              "      <th>Tep [°C]</th>\n",
              "      <th>Head Gap [mm]</th>\n",
              "      <th>File</th>\n",
              "      <th>Feature</th>\n",
              "      <th>absolute_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>bbuchr</td>\n",
              "      <td>150.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1</td>\n",
              "      <td>230523_Dataset01_Valeo_Nr01_0.png</td>\n",
              "      <td>dist.1</td>\n",
              "      <td>/content/drive/MyDrive/zerop/FTI Dataset 2023/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>bbuchr</td>\n",
              "      <td>150.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1</td>\n",
              "      <td>230523_Dataset01_Valeo_Nr01_0.png</td>\n",
              "      <td>e.rought1</td>\n",
              "      <td>/content/drive/MyDrive/zerop/FTI Dataset 2023/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>bbuchr</td>\n",
              "      <td>150.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1</td>\n",
              "      <td>230523_Dataset01_Valeo_Nr01_1.png</td>\n",
              "      <td>e.rought2</td>\n",
              "      <td>/content/drive/MyDrive/zerop/FTI Dataset 2023/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>bbuchr</td>\n",
              "      <td>150.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1</td>\n",
              "      <td>230523_Dataset01_Valeo_Nr01_1.png</td>\n",
              "      <td>e.rought3</td>\n",
              "      <td>/content/drive/MyDrive/zerop/FTI Dataset 2023/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>bbuchr</td>\n",
              "      <td>150.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1</td>\n",
              "      <td>230523_Dataset01_Valeo_Nr01_2.png</td>\n",
              "      <td>angle</td>\n",
              "      <td>/content/drive/MyDrive/zerop/FTI Dataset 2023/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba564009-291d-4568-992e-7d3989277f0b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba564009-291d-4568-992e-7d3989277f0b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba564009-291d-4568-992e-7d3989277f0b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c4e9ce4b-e889-4e1b-990f-0d097f9f4f85\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c4e9ce4b-e889-4e1b-990f-0d097f9f4f85')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c4e9ce4b-e889-4e1b-990f-0d097f9f4f85 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Surface Treatment [bbuchr; msahac]\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"bbuchr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 150.0,\n        \"max\": 150.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          150.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Resolution [dpi]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 300.0,\n        \"max\": 300.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          300.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rounding [AV]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 100.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Speed [mm/s]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 50.0,\n        \"max\": 50.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          50.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tep [\\u00b0C]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 42.0,\n        \"max\": 42.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          42.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Head Gap [mm]\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"File\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"230523_Dataset01_Valeo_Nr01_0.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"e.rought1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"absolute_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"/content/drive/MyDrive/zerop/FTI Dataset 2023/Datset_01_ValeoPart_01_23.5.2023/4_Microscope Images/230523_Dataset01_Valeo_Nr01_0.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.groupby('File').agg({\n",
        "    'Feature': lambda x: ','.join(x),\n",
        "    # 'Label': lambda x: ','.join(x),\n",
        "    'absolute_path': 'first'\n",
        "}).reset_index()"
      ],
      "metadata": {
        "id": "zGtokCMSS5p-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary mapping feature names to indices\n",
        "features_map = {\n",
        "    'dist.1': 0, 'e.rought1': 1, 'e.rought2': 2, 'e.rought3': 3,\n",
        "    'angle': 4, 'dist.6': 5, 'dots': 6, 'e.rought4': 7\n",
        "}\n",
        "\n",
        "# Create new columns for each feature initialized to 0\n",
        "for feature in features_map.keys():\n",
        "    df[feature] = 0\n",
        "\n",
        "# Update the new feature columns to 1 if the feature appears in the 'Feature' column\n",
        "for index, row in df.iterrows():\n",
        "    feature_list = row['Feature'].split(',')  # Split the comma-separated features\n",
        "    for feature in feature_list:\n",
        "        if feature in features_map:\n",
        "            df.at[index, feature] = 1\n",
        "\n",
        "# Remove the 'Feature' column since we now have the individual features as columns\n",
        "# df = df.drop(columns=['Feature'])\n",
        "\n",
        "# Optionally reset the index and remove any duplicates\n",
        "# df = df.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "pvd0FUWoSh9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "2d946946-5edc-4952-c85f-46ac94e1bc66"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     File                      Feature  \\\n",
              "0  20240719_Dataset001_PETSample_01_0.png                       dist.1   \n",
              "1  20240719_Dataset001_PETSample_01_1.png          e.rought2,e.rought3   \n",
              "2  20240719_Dataset001_PETSample_01_2.png  e.rought4,dots,dist.6,angle   \n",
              "3  20240719_Dataset001_PETSample_02_0.png             e.rought1,dist.1   \n",
              "4  20240719_Dataset001_PETSample_02_1.png          e.rought2,e.rought3   \n",
              "\n",
              "                                       absolute_path  dist.1  e.rought1  \\\n",
              "0  /content/drive/MyDrive/zerop_/FTI Dataset 2024...       1          0   \n",
              "1  /content/drive/MyDrive/zerop_/FTI Dataset 2024...       0          0   \n",
              "2  /content/drive/MyDrive/zerop_/FTI Dataset 2024...       0          0   \n",
              "3  /content/drive/MyDrive/zerop_/FTI Dataset 2024...       1          1   \n",
              "4  /content/drive/MyDrive/zerop_/FTI Dataset 2024...       0          0   \n",
              "\n",
              "   e.rought2  e.rought3  angle  dist.6  dots  e.rought4  \n",
              "0          0          0      0       0     0          0  \n",
              "1          1          1      0       0     0          0  \n",
              "2          0          0      1       1     1          1  \n",
              "3          0          0      0       0     0          0  \n",
              "4          1          1      0       0     0          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c46769dc-293a-4ba6-9d68-e94fe9c6c438\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Feature</th>\n",
              "      <th>absolute_path</th>\n",
              "      <th>dist.1</th>\n",
              "      <th>e.rought1</th>\n",
              "      <th>e.rought2</th>\n",
              "      <th>e.rought3</th>\n",
              "      <th>angle</th>\n",
              "      <th>dist.6</th>\n",
              "      <th>dots</th>\n",
              "      <th>e.rought4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20240719_Dataset001_PETSample_01_0.png</td>\n",
              "      <td>dist.1</td>\n",
              "      <td>/content/drive/MyDrive/zerop_/FTI Dataset 2024...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20240719_Dataset001_PETSample_01_1.png</td>\n",
              "      <td>e.rought2,e.rought3</td>\n",
              "      <td>/content/drive/MyDrive/zerop_/FTI Dataset 2024...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20240719_Dataset001_PETSample_01_2.png</td>\n",
              "      <td>e.rought4,dots,dist.6,angle</td>\n",
              "      <td>/content/drive/MyDrive/zerop_/FTI Dataset 2024...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20240719_Dataset001_PETSample_02_0.png</td>\n",
              "      <td>e.rought1,dist.1</td>\n",
              "      <td>/content/drive/MyDrive/zerop_/FTI Dataset 2024...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20240719_Dataset001_PETSample_02_1.png</td>\n",
              "      <td>e.rought2,e.rought3</td>\n",
              "      <td>/content/drive/MyDrive/zerop_/FTI Dataset 2024...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c46769dc-293a-4ba6-9d68-e94fe9c6c438')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c46769dc-293a-4ba6-9d68-e94fe9c6c438 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c46769dc-293a-4ba6-9d68-e94fe9c6c438');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e0fe8e3-55db-49a8-8df3-03614ddce116\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e0fe8e3-55db-49a8-8df3-03614ddce116')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e0fe8e3-55db-49a8-8df3-03614ddce116 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 607,\n  \"fields\": [\n    {\n      \"column\": \"File\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 607,\n        \"samples\": [\n          \"230616_Dataset48_Valeo_Nr14_7.png\",\n          \"230530_Dataset13_Valeo_Nr04_4.png\",\n          \"20240725_Dataset009_PPSample_02_2.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Feature\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"angle,dist.6,e.rought4\",\n          \"dist.1,e.rought1\",\n          \"e.rought1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"absolute_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 607,\n        \"samples\": [\n          \"/content/drive/MyDrive/zerop/FTI Dataset 2023/Datset_48_ValeoPart_14_16.6.2023/4_Microscope Images/230616_Dataset48_Valeo_Nr14_7.png\",\n          \"/content/drive/MyDrive/zerop/FTI Dataset 2023/Datset_13_ValeoPart_04_30.5.2023/4_Microscope Images/230530_Dataset13_Valeo_Nr04_4.png\",\n          \"/content/drive/MyDrive/zerop_/FTI Dataset 2024/Datset_009_PPSample_01_25.07.2024/4_Microscope Images - Copy/20240725_Dataset009_PPSample_02_2.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dist.1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"e.rought1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"e.rought2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"e.rought3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"angle\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dist.6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dots\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"e.rought4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "RpLVHOVeoESX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99bca70a-f9cf-409a-bd52-ba1221b930ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(607, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, features, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.features = features\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image using OpenCV\n",
        "        img_path = self.image_paths[idx]\n",
        "        features = self.features[idx]\n",
        "\n",
        "        # Read the image in grayscale mode (equivalent to 'L' in PIL)\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Convert to PIL image to apply the same transform (if necessary)\n",
        "        if self.transform:\n",
        "            image = Image.fromarray(image)\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Convert features to tensor\n",
        "        features = torch.tensor(features).float()\n",
        "\n",
        "        return image, features\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n"
      ],
      "metadata": {
        "id": "Mg5I2J1XfiuP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# transform_train = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)), #(256, 256)\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.RandomVerticalFlip(),\n",
        "#     transforms.RandomRotation(degrees=(0, 90)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "# ])\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(degrees=(0, 90)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.GaussianBlur(kernel_size=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "])\n",
        "\n",
        "transform_valid = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "])"
      ],
      "metadata": {
        "id": "fbDvkfdefn3U"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# List of features (from the original feature_to_idx)\n",
        "feature_columns = ['dist.1', 'e.rought1', 'e.rought2', 'e.rought3', 'angle', 'dist.6', 'dots', 'e.rought4']\n",
        "\n",
        "def split_data(df, test_size=0.18, random_state=40):\n",
        "    # Split the data into train and test sets\n",
        "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Prepare file paths\n",
        "    X_train = train_df['absolute_path'].tolist()\n",
        "    X_test = test_df['absolute_path'].tolist()\n",
        "\n",
        "    # Select feature columns for training and testing (already in binary form)\n",
        "    features_train = train_df[feature_columns].values  # Convert to numpy array\n",
        "    features_test = test_df[feature_columns].values    # Convert to numpy array\n",
        "    # y_train = train_df['Label'].values if 'Label' in train_df.columns else None\n",
        "    # y_test = test_df['Label'].values if 'Label' in test_df.columns else None\n",
        "\n",
        "    return X_train, X_test, features_train, features_test"
      ],
      "metadata": {
        "id": "MVFsjJTjfsse"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, features_train, features_test = split_data(df)"
      ],
      "metadata": {
        "id": "eXGU41o4fy0G"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(features_train), len(features_test), len(X_train), len(X_test)"
      ],
      "metadata": {
        "id": "_hHjtT4of2CJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8325399-65f2-44c4-86bd-98d2349b5fc5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(497, 110, 497, 110)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_train[0], features_train[1], features_train[2]"
      ],
      "metadata": {
        "id": "m2mgz6smt1_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ed9403-6a07-4116-cb72-14dbbb6ef31f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 1, 0, 0, 0, 0, 0, 0]),\n",
              " array([1, 1, 0, 0, 0, 0, 0, 0]),\n",
              " array([0, 0, 1, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train[0], y_train[1], y_train[2]"
      ],
      "metadata": {
        "id": "jIUXyO3Sr4DM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_feature_weights(features_train, device):\n",
        "    # Count occurrences of each feature\n",
        "    feature_counts = np.sum(features_train, axis=0)\n",
        "\n",
        "    # Calculate weights (inverse of frequency)\n",
        "    n_samples = features_train.shape[0]\n",
        "    feature_frequencies = feature_counts / n_samples\n",
        "\n",
        "    # Normalize weights\n",
        "    epsilon = 1e-7\n",
        "    inverse_frequencies = 1 / (feature_frequencies + epsilon)\n",
        "    weights = inverse_frequencies / np.sum(inverse_frequencies)\n",
        "    feature_weights = torch.FloatTensor(weights).to(device)\n",
        "\n",
        "    return feature_weights\n",
        "\n",
        "# Assuming you have your features_train and y_train from the split_data function\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "feature_weights = calculate_feature_weights(features_train, device)\n",
        "# label_weights = calculate_feature_weights(y_train, device)\n",
        "\n",
        "print(f\"Feature Weights: {feature_weights}\")\n",
        "# print(f\"Label Weights: {label_weights}\")"
      ],
      "metadata": {
        "id": "ihnGtbGEJBz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3230f4a-4bfb-412f-fdb2-a1b9a4164453"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Weights: tensor([0.1184, 0.1292, 0.1192, 0.1209, 0.1292, 0.1354, 0.1184, 0.1292],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train, features_train, transform=transform_train)\n",
        "test_dataset = CustomDataset(X_test, features_test, transform=transform_valid)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16,  num_workers=2, shuffle=True)\n",
        "valid_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "yjn24viCf4c3"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator = iter(train_loader)\n",
        "data = next(train_iterator)\n",
        "print(data[0].shape, data[1].shape)"
      ],
      "metadata": {
        "id": "077w_1scf7wQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6428960f-0e2e-4174-abca-0cab44a46176"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1, 224, 224]) torch.Size([16, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiFeatureModel(nn.Module):\n",
        "    def __init__(self, num_features, feature_weights=None):\n",
        "        super().__init__()\n",
        "        self.base_model = models.mobilenet_v2().features\n",
        "        self.base_model[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "        last_channel = models.mobilenet_v2().last_channel\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.heads = nn.ModuleList(\n",
        "            [nn.Sequential(\n",
        "                nn.Dropout(p=0.2),\n",
        "                nn.Linear(in_features=last_channel, out_features=1)  # Single output for each feature\n",
        "            ) for _ in range(num_features)]\n",
        "        )\n",
        "        self.feature_weights = feature_weights\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        feature_outputs = [head(x) for head in self.heads]\n",
        "\n",
        "        return torch.cat(feature_outputs, dim=1)\n",
        "\n",
        "    def weighted_feature_cross_entropy(self, input, target):\n",
        "        # , pos_weight=self.feature_weights\n",
        "        return F.binary_cross_entropy_with_logits(input, target)\n",
        "\n",
        "    # def get_loss(self, net_output, ground_truth):\n",
        "    #     # Compute binary cross-entropy loss for each feature\n",
        "    #     loss = F.binary_cross_entropy(net_output, ground_truth)\n",
        "    #     return loss"
      ],
      "metadata": {
        "id": "b8UhlyOVdNko"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadFeatureModel(nn.Module):\n",
        "    def __init__(self, num_features, num_labels ,feature_weights=None, label_weights=None):\n",
        "        super().__init__()\n",
        "        self.base_model = models.mobilenet_v2().features\n",
        "        self.base_model[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "        last_channel = models.mobilenet_v2().last_channel\n",
        "\n",
        "        # Pooling layer to reduce dimensions\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.feature_weights = feature_weights\n",
        "        self.label_weights = label_weights\n",
        "        # Create separate heads for each feature\n",
        "        self.heads_f = nn.ModuleList(\n",
        "            [nn.Sequential(\n",
        "                nn.Dropout(p=0.2),\n",
        "                nn.Linear(in_features=last_channel, out_features=1)  # Single output for each feature\n",
        "            ) for _ in range(num_features)]\n",
        "        )\n",
        "        self.heads_l = nn.ModuleList(\n",
        "            [nn.Sequential(\n",
        "                nn.Dropout(p=0.2),\n",
        "                nn.Linear(in_features=last_channel, out_features=1)  # Single output for each feature\n",
        "            ) for _ in range(num_labels)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "        # Get outputs from each head\n",
        "        feature_outputs = [head(x) for head in self.heads_f]\n",
        "        label_outputs = [head(x) for head in self.heads_l]\n",
        "\n",
        "\n",
        "        # Stack outputs to create a single tensor with shape (batch_size, num_features)\n",
        "        return torch.cat(feature_outputs, dim=1) , torch.cat(label_outputs, dim=1)\n",
        "\n",
        "    def weighted_feature_cross_entropy(self, input, target):\n",
        "        return F.binary_cross_entropy_with_logits(input, target, pos_weight=self.feature_weights)\n",
        "    def weighted_label_cross_entropy(self, input, target):\n",
        "        return F.binary_cross_entropy_with_logits(input, target, pos_weight=self.label_weights)"
      ],
      "metadata": {
        "id": "kcIe91UGhVOH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetWithMultiHead(nn.Module):\n",
        "    def __init__(self, num_feature_classes, feature_weights):\n",
        "        super(ResNetWithMultiHead, self).__init__()\n",
        "\n",
        "        # Load the pre-trained ResNet model\n",
        "        self.backbone = models.resnet18(pretrained=True)\n",
        "\n",
        "        # Modify the first convolutional layer to accept 1-channel input if necessary\n",
        "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=6, stride=2, padding=3, bias=True)\n",
        "\n",
        "        # Extract the number of features from the fully connected layer\n",
        "        num_ftrs = self.backbone.fc.in_features\n",
        "\n",
        "        # Remove the original fully connected layer (fc)\n",
        "        self.backbone.fc = nn.Identity()  # Acts as a pass-through layer\n",
        "\n",
        "        # Shared features processing\n",
        "        self.shared_fc = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        # Create separate heads for each feature\n",
        "        self.feature_heads = nn.ModuleList(\n",
        "            [nn.Linear(128, 1) for _ in range(num_feature_classes)]  # One head for each feature\n",
        "        )\n",
        "\n",
        "        # Store the feature weights\n",
        "        self.register_buffer('feature_weights', feature_weights)\n",
        "\n",
        "    def forward(self, image):\n",
        "        # Forward pass through the backbone\n",
        "        x = self.backbone(image)\n",
        "\n",
        "        # Process features\n",
        "        shared_features = self.shared_fc(x)\n",
        "\n",
        "        # Collect outputs from each feature head\n",
        "        feature_outputs = [head(shared_features) for head in self.feature_heads]\n",
        "\n",
        "        # Stack outputs to create a single tensor with shape (batch_size, num_feature_classes)\n",
        "        return torch.cat(feature_outputs, dim=1)  # Shape will be (batch_size, num_feature_classes)\n",
        "\n",
        "    def weighted_feature_cross_entropy(self, input, target):\n",
        "        return F.binary_cross_entropy_with_logits(input, target) #, pos_weight=self.feature_weights\n"
      ],
      "metadata": {
        "id": "Yf99PtZzf-As"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "QQdtGWTvnAvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9533306d-6d48-40b0-8b42-fba46b9069bd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-1.0.10-py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Downloading timm-1.0.10-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: timm\n",
            "Successfully installed timm-1.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from timm import create_model  # Import from timm for pretrained ViT\n",
        "\n",
        "class ViTWithFeatureHead(nn.Module):\n",
        "    def __init__(self, num_feature_classes, feature_weights):\n",
        "        super(ViTWithFeatureHead, self).__init__()\n",
        "\n",
        "        # Load the smaller pre-trained Vision Transformer (ViT)\n",
        "        self.backbone = create_model('vit_small_patch16_224', pretrained=True)\n",
        "        self.backbone.patch_embed.proj = nn.Conv2d(1, 384, kernel_size=16, stride=16)\n",
        "\n",
        "        # Extract the number of features from the ViT model's classification head\n",
        "        num_ftrs = self.backbone.head.in_features\n",
        "\n",
        "        # Remove the original classification head (fc)\n",
        "        self.backbone.head = nn.Identity()  # Acts as a pass-through layer\n",
        "\n",
        "        for name, param in self.backbone.named_parameters():\n",
        "            if \"head\" in name:  # Freeze the head (last layer)\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Shared features processing (simplified fully connected layer)\n",
        "        self.shared_fc = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        # Feature head\n",
        "        self.feature_head = nn.Linear(256, num_feature_classes)\n",
        "\n",
        "        # Store the feature weights for loss calculation\n",
        "        self.register_buffer('feature_weights', feature_weights)\n",
        "\n",
        "    def forward(self, image):\n",
        "        # Forward pass through the backbone (ViT model)\n",
        "        x = self.backbone(image)\n",
        "\n",
        "        # Process features with simplified fully connected layer\n",
        "        shared_features = self.shared_fc(x)\n",
        "\n",
        "        # Output from feature head\n",
        "        feature_output = self.feature_head(shared_features)\n",
        "\n",
        "        return feature_output\n",
        "\n",
        "    def weighted_feature_cross_entropy(self, input, target):\n",
        "        return F.binary_cross_entropy_with_logits(input, target, pos_weight=self.feature_weights)\n"
      ],
      "metadata": {
        "id": "3YAaJS14m9WB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timm import create_model\n",
        "\n",
        "class ResNetWithFeatureHead(nn.Module):\n",
        "    def __init__(self, num_feature_classes, feature_weights):\n",
        "        super(ResNetWithFeatureHead, self).__init__()\n",
        "\n",
        "        # Load the pre-trained SEResNet50 model\n",
        "        self.backbone = create_model('seresnet50', pretrained=True)\n",
        "\n",
        "        # Modify the first convolutional layer to accept 1-channel input\n",
        "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "        # Extract the number of features from the backbone's output\n",
        "        self.backbone.fc = nn.Identity()  # Acts as a pass-through layer\n",
        "\n",
        "        # Set num_ftrs to 2048 (the expected output size after the backbone)\n",
        "        num_ftrs = 2048\n",
        "\n",
        "        # Shared features processing\n",
        "        self.shared_fc = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, 256),  # Set input size to 2048\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "\n",
        "        # Feature head\n",
        "        self.feature_head = nn.Linear(256, num_feature_classes)\n",
        "\n",
        "        # Store the feature weights for loss calculation\n",
        "        self.register_buffer('feature_weights', feature_weights)\n",
        "\n",
        "    def forward(self, image):\n",
        "        # Forward pass through the backbone (ResNet model)\n",
        "        x = self.backbone(image)\n",
        "\n",
        "        # Process features with shared fully connected layers\n",
        "        shared_features = self.shared_fc(x)\n",
        "\n",
        "        # Output from feature head\n",
        "        feature_output = self.feature_head(shared_features)\n",
        "\n",
        "        return feature_output\n",
        "\n",
        "    def weighted_feature_cross_entropy(self, input, target):\n",
        "        return nn.functional.binary_cross_entropy_with_logits(input, target, pos_weight=self.feature_weights)\n"
      ],
      "metadata": {
        "id": "g22z2gbNuiOj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model and move it to the device\n",
        "# model = ResNetWithFeatureHead(num_feature_classes=8, feature_weights=feature_weights)\n",
        "# model = ViTWithFeatureHead(num_feature_classes=8, feature_weights=feature_weights)\n",
        "model = ResNetWithMultiHead(num_feature_classes=8, feature_weights=feature_weights)\n",
        "# model = MultiHeadFeatureModel(num_features=8, num_labels=4, feature_weights=feature_weights, label_weights=label_weights)\n",
        "# model = MultiFeatureModel(num_features=8, feature_weights=feature_weights)\n",
        "\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "# for name, param in model.named_parameters():\n",
        "#     if param.grad is not None:\n",
        "#         print(f\"{name} gradient: {param.grad.abs().mean().item()}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WYh_AGzeing2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "780975df-b809-4086-92b6-bae959ad0a8e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 49.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetWithMultiHead(\n",
              "  (backbone): ResNet(\n",
              "    (conv1): Conv2d(1, 64, kernel_size=(6, 6), stride=(2, 2), padding=(3, 3))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Identity()\n",
              "  )\n",
              "  (shared_fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (feature_heads): ModuleList(\n",
              "    (0-7): 8 x Linear(in_features=128, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWcc8RoW0O0L",
        "outputId": "59695a76-3dc0-4f83-914b-84cdb61cb300"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.4.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (71.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Downloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.7 torchmetrics-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from tqdm import tqdm\n",
        "from torchmetrics.classification import MultilabelPrecision, MultilabelRecall, MultilabelF1Score\n",
        "import numpy as np\n",
        "import copy\n",
        "from torch.cuda.amp import autocast, GradScaler  # For mixed precision\n",
        "\n",
        "def model_train(model, train_loader, valid_loader, device, n_epochs, learning_rate, wd):\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=wd)\n",
        "\n",
        "    # Reduce LR on plateau: monitor validation accuracy, and reduce if no improvement\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "    scaler = torch.amp.GradScaler()  # For mixed precision training\n",
        "\n",
        "    # Best validation accuracy tracking\n",
        "    best_val_acc = -np.inf\n",
        "    best_weights = None\n",
        "    num_features = 8\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total_train = 0\n",
        "        feature_correct_train = 0\n",
        "\n",
        "        # Training loop\n",
        "        with tqdm(enumerate(train_loader), total=len(train_loader), unit=\"batch\") as bar:\n",
        "            bar.set_description(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
        "            for batch_idx, (imgs, feature_targets) in bar:\n",
        "                imgs, feature_targets = imgs.to(device), feature_targets.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Mixed precision forward pass\n",
        "                with torch.amp.autocast(device_type=device.type):\n",
        "                    feature_outputs = model(imgs)\n",
        "\n",
        "                    # Compute the losses\n",
        "                    feature_loss = model.weighted_feature_cross_entropy(feature_outputs, feature_targets)\n",
        "                    loss = feature_loss\n",
        "\n",
        "                # Backpropagation and optimization\n",
        "                scaler.scale(loss).backward()\n",
        "                # Log gradient norms before stepping\n",
        "                # for name, param in model.named_parameters():\n",
        "                #     if param.grad is not None:\n",
        "                #         print(f\"Layer: {name} | Gradient Norm: {param.grad.norm()}\")\n",
        "\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                # Accuracy calculation: apply sigmoid and threshold\n",
        "                feature_outputs_probs = torch.sigmoid(feature_outputs)\n",
        "                feature_preds = (feature_outputs_probs > 0.3).float()  # Apply threshold\n",
        "                # print(f\"Raw logits: {feature_outputs}\")\n",
        "                # print(f\"Sigmoid outputs: {feature_outputs_probs}\")\n",
        "                # print(f\"Predictions (after thresholding): {feature_preds}\")\n",
        "                # print(f\"Targets: {feature_targets}\")\n",
        "                # Accuracy for feature head\n",
        "                feature_correct_train += (feature_preds == feature_targets).float().sum().item()\n",
        "                total_train += feature_targets.numel()\n",
        "\n",
        "                # Training accuracy (correct predictions / total number of labels)\n",
        "                train_acc_feature = feature_correct_train / total_train\n",
        "\n",
        "                bar.set_postfix(\n",
        "                    loss=running_loss / (batch_idx + 1),\n",
        "                    feature_acc=train_acc_feature,\n",
        "                    lr=scheduler.get_last_lr()[0]\n",
        "                )\n",
        "\n",
        "        # Validation phase with metrics tracking (precision, recall, F1)\n",
        "        model.eval()\n",
        "        precision = MultilabelPrecision(num_labels=num_features).to(device)\n",
        "        recall = MultilabelRecall(num_labels=num_features).to(device)\n",
        "        f1_score = MultilabelF1Score(num_labels=num_features).to(device)\n",
        "\n",
        "        feature_correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, feature_targets in valid_loader:\n",
        "                imgs, feature_targets = imgs.to(device), feature_targets.to(device)\n",
        "\n",
        "                # Forward pass (no mixed precision for validation)\n",
        "                feature_outputs = model(imgs)\n",
        "\n",
        "                # Sigmoid activation for multi-label output\n",
        "                feature_outputs_probs = torch.sigmoid(feature_outputs)\n",
        "                feature_preds = (feature_outputs_probs > 0.3).float()  # Apply threshold\n",
        "\n",
        "                # Track precision, recall, and F1\n",
        "                precision.update(feature_preds, feature_targets)\n",
        "                recall.update(feature_preds, feature_targets)\n",
        "                f1_score.update(feature_preds, feature_targets)\n",
        "\n",
        "                # Accuracy for feature head\n",
        "                feature_correct_val += (feature_preds == feature_targets).float().sum().item()\n",
        "                total_val += feature_targets.numel()\n",
        "\n",
        "        val_acc_feature = feature_correct_val / total_val\n",
        "        precision_score = precision.compute().mean().item()\n",
        "        recall_score = recall.compute().mean().item()\n",
        "        f1_score_value = f1_score.compute().mean().item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1} Validation Accuracy - Feature: {val_acc_feature * 100:.2f}%\")\n",
        "        print(f\"Precision: {precision_score:.4f}, Recall: {recall_score:.4f}, F1: {f1_score_value:.4f}\")\n",
        "\n",
        "        # Save the best model weights based on validation accuracy\n",
        "        if val_acc_feature > best_val_acc:\n",
        "            best_val_acc = val_acc_feature\n",
        "            best_weights = copy.deepcopy(model.state_dict())\n",
        "            print(f\"Best validation accuracy ({best_val_acc * 100:.2f}%)\")\n",
        "\n",
        "        # Scheduler step: Reduce learning rate if validation accuracy plateaus\n",
        "        scheduler.step(val_acc_feature)\n",
        "\n",
        "    # Return the best validation accuracy and the model's best weights\n",
        "    return best_val_acc, best_weights"
      ],
      "metadata": {
        "id": "0OIgRTUqin3T"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc, best_weights = model_train(model, train_loader, valid_loader, device, n_epochs=50, learning_rate=1e-3, wd= 1e-6)\n",
        "if best_acc > 0.895:\n",
        "    accuracy_str = f'{best_acc * 100:.2f}'.replace('.', '_')\n",
        "    save_path = f'/content/drive/MyDrive/Results/saved_models/resnet18/filtered/best_model_{accuracy_str}.pth'\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    torch.save(best_weights , save_path)\n",
        "    # model.load_state_dict(best_weights)\n",
        "    print(f\"Saved the Best Accuracy: {best_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "TLfJa4QVcsF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "59b1f6bc-2b87-4235-8f48-40934976f139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "Epoch 1/50: 100%|██████████| 32/32 [00:35<00:00,  1.11s/batch, feature_acc=0.705, loss=0.457, lr=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Validation Accuracy - Feature: 68.52%\n",
            "Precision: 0.6994, Recall: 0.3742, F1: 0.3101\n",
            "Best validation accuracy (68.52%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|██████████| 32/32 [00:40<00:00,  1.25s/batch, feature_acc=0.884, loss=0.302, lr=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Validation Accuracy - Feature: 69.66%\n",
            "Precision: 0.6643, Recall: 0.4565, F1: 0.4254\n",
            "Best validation accuracy (69.66%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|██████████| 32/32 [00:35<00:00,  1.11s/batch, feature_acc=0.904, loss=0.264, lr=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Validation Accuracy - Feature: 85.57%\n",
            "Precision: 0.7216, Recall: 0.8194, F1: 0.7546\n",
            "Best validation accuracy (85.57%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|██████████| 32/32 [00:35<00:00,  1.10s/batch, feature_acc=0.919, loss=0.255, lr=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Validation Accuracy - Feature: 75.68%\n",
            "Precision: 0.6517, Recall: 0.8138, F1: 0.6556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|██████████| 32/32 [00:39<00:00,  1.22s/batch, feature_acc=0.92, loss=0.232, lr=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Validation Accuracy - Feature: 87.95%\n",
            "Precision: 0.7550, Recall: 0.8727, F1: 0.8004\n",
            "Best validation accuracy (87.95%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|██████████| 32/32 [00:35<00:00,  1.11s/batch, feature_acc=0.924, loss=0.21, lr=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Validation Accuracy - Feature: 92.95%\n",
            "Precision: 0.8015, Recall: 0.9955, F1: 0.8859\n",
            "Best validation accuracy (92.95%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|██████████| 32/32 [00:39<00:00,  1.24s/batch, feature_acc=0.926, loss=0.229, lr=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Validation Accuracy - Feature: 93.41%\n",
            "Precision: 0.8087, Recall: 1.0000, F1: 0.8927\n",
            "Best validation accuracy (93.41%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|██████████| 32/32 [00:35<00:00,  1.12s/batch, feature_acc=0.929, loss=0.25, lr=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Validation Accuracy - Feature: 92.50%\n",
            "Precision: 0.7930, Recall: 0.9832, F1: 0.8769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|██████████| 32/32 [00:37<00:00,  1.16s/batch, feature_acc=0.925, loss=0.24, lr=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Validation Accuracy - Feature: 90.57%\n",
            "Precision: 0.7637, Recall: 0.9642, F1: 0.8486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|██████████| 32/32 [00:35<00:00,  1.11s/batch, feature_acc=0.907, loss=0.257, lr=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Validation Accuracy - Feature: 92.84%\n",
            "Precision: 0.8012, Recall: 0.9914, F1: 0.8838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|██████████| 32/32 [00:38<00:00,  1.21s/batch, feature_acc=0.924, loss=0.218, lr=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Validation Accuracy - Feature: 92.27%\n",
            "Precision: 0.7896, Recall: 0.9921, F1: 0.8767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50:  78%|███████▊  | 25/32 [00:30<00:06,  1.01batch/s, feature_acc=0.933, loss=0.188, lr=0.0001]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eq2NKW_gCqFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Initialize a tensor to hold the sum of labels for each class\n",
        "num_classes = train_loader.dataset[0][1].shape[0]  # assuming dataset returns (image, labels)\n",
        "label_counts = torch.zeros(num_classes)\n",
        "\n",
        "# Iterate over the dataset to count labels\n",
        "for _, labels in train_loader:\n",
        "    label_counts += labels.sum(dim=0)  # Summing positive labels for each class\n",
        "\n",
        "# Convert to numpy for plotting\n",
        "label_counts = label_counts.cpu().numpy()\n",
        "\n",
        "# Plot the distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(np.arange(num_classes), label_counts)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of positive labels')\n",
        "plt.title('Training Labels Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gKxbR0nkc0hR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "44ec0763-f84d-43d9-d075-d3deda789a29"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PqKxJT4d9xNi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}